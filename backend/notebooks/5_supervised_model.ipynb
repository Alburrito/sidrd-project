{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reports = pd.read_pickle('data/preprocessed_reports.pkl')\n",
    "df_report_pairs = pd.read_pickle('data/preprocessed_report_pairs.pkl')\n",
    "\n",
    "tfidf1L = pickle.load(open('data/vectorizer/tfidf1L.pkl', 'rb'))\n",
    "tfidf2L = pickle.load(open('data/vectorizer/tfidf2L.pkl', 'rb'))\n",
    "tfidf3L = pickle.load(open('data/vectorizer/tfidf3L.pkl', 'rb'))\n",
    "tfidf4L = pickle.load(open('data/vectorizer/tfidf4L.pkl', 'rb'))\n",
    "tfidf1S = pickle.load(open('data/vectorizer/tfidf1S.pkl', 'rb'))\n",
    "tfidf2S = pickle.load(open('data/vectorizer/tfidf2S.pkl', 'rb'))\n",
    "tfidf3S = pickle.load(open('data/vectorizer/tfidf3S.pkl', 'rb'))\n",
    "tfidf4S = pickle.load(open('data/vectorizer/tfidf4S.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('data/svm/'): os.makedirs('data/svm/') \n",
    "if not os.path.exists('data/rfc/'): os.makedirs('data/rfc/') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'id_M', 'id_D', 'statusM', 'statusD', 'componentM',\n",
       "       'componentD', 'summaryM', 'summaryD', 'commentsM', 'commentsD',\n",
       "       'text1M', 'text1D', 'text2M', 'text2D', 'text3M', 'text3D', 'text4M',\n",
       "       'text4D', 'tokens1ML', 'tokens2ML', 'tokens3ML', 'tokens4ML',\n",
       "       'tokens1DL', 'tokens2DL', 'tokens3DL', 'tokens4DL', 'tokens1MS',\n",
       "       'tokens2MS', 'tokens3MS', 'tokens4MS', 'tokens1DS', 'tokens2DS',\n",
       "       'tokens3DS', 'tokens4DS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_pairs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A cada reporte M y D de cada par se aplicaría:\n",
    "# textP = textM + textD\n",
    "# tokensP = tokenizer(textP)\n",
    "# Para ahorrar tiempo se usarán los tokens ya obtenidos\n",
    "\n",
    "df_report_pairs['text1P'] = df_report_pairs['text1M'] + df_report_pairs['text1D']\n",
    "df_report_pairs['text2P'] = df_report_pairs['text2M'] + df_report_pairs['text2D']\n",
    "df_report_pairs['text3P'] = df_report_pairs['text3M'] + df_report_pairs['text3D']\n",
    "df_report_pairs['text4P'] = df_report_pairs['text4M'] + df_report_pairs['text4D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_pairs['tokens1PL'] = df_report_pairs['tokens1ML'] + df_report_pairs['tokens1DL']\n",
    "df_report_pairs['tokens2PL'] = df_report_pairs['tokens2ML'] + df_report_pairs['tokens2DL']\n",
    "df_report_pairs['tokens3PL'] = df_report_pairs['tokens3ML'] + df_report_pairs['tokens3DL']\n",
    "df_report_pairs['tokens4PL'] = df_report_pairs['tokens4ML'] + df_report_pairs['tokens4DL']\n",
    "df_report_pairs['tokens1PS'] = df_report_pairs['tokens1MS'] + df_report_pairs['tokens1DS']\n",
    "df_report_pairs['tokens2PS'] = df_report_pairs['tokens2MS'] + df_report_pairs['tokens2DS']\n",
    "df_report_pairs['tokens3PS'] = df_report_pairs['tokens3MS'] + df_report_pairs['tokens3DS']\n",
    "df_report_pairs['tokens4PS'] = df_report_pairs['tokens4MS'] + df_report_pairs['tokens4DS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1L = tfidf1L.transform(df_report_pairs['tokens1PL'].apply(' '.join)).toarray()\n",
    "data2L = tfidf2L.transform(df_report_pairs['tokens2PL'].apply(' '.join)).toarray()\n",
    "data3L = tfidf3L.transform(df_report_pairs['tokens3PL'].apply(' '.join)).toarray()\n",
    "data4L = tfidf4L.transform(df_report_pairs['tokens4PL'].apply(' '.join)).toarray()\n",
    "data1S = tfidf1S.transform(df_report_pairs['tokens1PS'].apply(' '.join)).toarray()\n",
    "data2S = tfidf2S.transform(df_report_pairs['tokens2PS'].apply(' '.join)).toarray()\n",
    "data3S = tfidf3S.transform(df_report_pairs['tokens3PS'].apply(' '.join)).toarray()\n",
    "data4S = tfidf4S.transform(df_report_pairs['tokens4PS'].apply(' '.join)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 7396) (5000, 7419) (5000, 19642) (5000, 9178) \n",
      " (5000, 6104) (5000, 6121) (5000, 16974) (5000, 7597)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    data1L.shape,  data2L.shape, data3L.shape, data4L.shape, '\\n',\n",
    "    data1S.shape,  data2S.shape, data3S.shape, data4S.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4000\n",
       "1    1000\n",
       "Name: duplicate, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_pairs['duplicate'] = df_report_pairs['type'].apply(lambda x: 0 if x=='master' else 1)\n",
    "df_report_pairs['duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de los conjuntos de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df_report_pairs['duplicate'].values\n",
    "\n",
    "x1L_train, x1L_test, y_train, y_test = train_test_split(data1L, y, test_size=0.2, random_state=42)\n",
    "x2L_train, x2L_test, y_train, y_test = train_test_split(data2L, y, test_size=0.2, random_state=42)\n",
    "x3L_train, x3L_test, y_train, y_test = train_test_split(data3L, y, test_size=0.2, random_state=42)\n",
    "x4L_train, x4L_test, y_train, y_test = train_test_split(data4L, y, test_size=0.2, random_state=42)\n",
    "x1S_train, x1S_test, y_train, y_test = train_test_split(data1S, y, test_size=0.2, random_state=42)\n",
    "x2S_train, x2S_test, y_train, y_test = train_test_split(data2S, y, test_size=0.2, random_state=42)\n",
    "x3S_train, x3S_test, y_train, y_test = train_test_split(data3S, y, test_size=0.2, random_state=42)\n",
    "x4S_train, x4S_test, y_train, y_test = train_test_split(data4S, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 7396), (1000, 7396), (4000,), (1000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1L_train.shape, x1L_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x1L_train), type(x1L_test), type(y_train), type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.int64, numpy.int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x1L_train[0]), type(x1L_test[0]), type(y_train[0]), type(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Máquinas de soporte vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def fit_svm(x_train, y_train, x_test, y_test) -> dict:\n",
    "    \"\"\"\n",
    "    Fits a svm classifier using x_train and y_train\n",
    "    Calculates classification metrics and returns it with the model\n",
    "    No hyperparameters are tuned\n",
    "    :returns: dict with keys\n",
    "        - model: SVClassifier\n",
    "        - accuracy: float\n",
    "        - confusion_matrix: np.array\n",
    "        - classification_report: str\n",
    "    \"\"\"\n",
    "    svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "    svm.fit(x_train, y_train)\n",
    "    y_pred = svm.predict(x_test)\n",
    "    return {\n",
    "        'model': svm,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'classification_report': classification_report(y_test, y_pred, zero_division=0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_results(title: str, svm_results: dict):\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(f\"Resultados del entrenamiento: {title}\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(f\"Accuracy: {svm_results['accuracy']}\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(\"Matriz de Confusión\")\n",
    "    print(\"-------------------------------\")\n",
    "    print(svm_results['confusion_matrix'])\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(\"Reporte de Clasificación\")\n",
    "    print(\"-------------------------------\")\n",
    "    print(svm_results['classification_report'])\n",
    "    print(\"-------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1L_results = fit_svm(x1L_train, y_train, x1L_test, y_test); show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 1L\",svm1L_results)\n",
    "pickle.dump(svm1L_results, open('svm/svm1L_results.pkl', 'wb'))\n",
    "\n",
    "svm2L_results = fit_svm(x2L_train, y_train, x2L_test, y_test); show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 2L\",svm2L_results)\n",
    "pickle.dump(svm2L_results, open('svm/svm2L_results.pkl', 'wb'))\n",
    "\n",
    "svm3L_results = fit_svm(x3L_train, y_train, x3L_test, y_test); show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 3L\",svm3L_results)\n",
    "pickle.dump(svm3L_results, open('svm/svm3L_results.pkl', 'wb'))\n",
    "\n",
    "svm4L_results = fit_svm(x4L_train, y_train, x4L_test, y_test); show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 4L\",svm4L_results)\n",
    "pickle.dump(svm4L_results, open('svm/svm4L_results.pkl', 'wb'))\n",
    "\n",
    "svm1S_results = fit_svm(x1S_train, y_train, x1S_test, y_test); show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 1S\",svm1S_results)\n",
    "pickle.dump(svm1S_results, open('svm/svm1S_results.pkl', 'wb'))\n",
    "\n",
    "svm2S_results = fit_svm(x2S_train, y_train, x2S_test, y_test); show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 2S\",svm2S_results)\n",
    "pickle.dump(svm2S_results, open('svm/svm2S_results.pkl', 'wb'))\n",
    "\n",
    "svm3S_results = fit_svm(x3S_train, y_train, x3S_test, y_test); show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 3S\",svm3S_results)\n",
    "pickle.dump(svm3S_results, open('svm/svm3S_results.pkl', 'wb'))\n",
    "\n",
    "svm4S_results = fit_svm(x4S_train, y_train, x4S_test, y_test); show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 4S\",svm4S_results)\n",
    "pickle.dump(svm4S_results, open('svm/svm4S_results.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "Resultados del entrenamiento con Máquina de Soporte Vectorial (SVM)\n",
      "CONJUNTO: SUPPORT VECTOR MACHINE - CONJUNTO 1L\n",
      "-------------------------------------------------------------------\n",
      "Accuracy: 0.837\n",
      "-------------------------------------------------------------------\n",
      "Matriz de Confusión\n",
      "-------------------------------\n",
      "[[758  26]\n",
      " [137  79]]\n",
      "-------------------------------------------------------------------\n",
      "Reporte de Clasificación\n",
      "-------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90       784\n",
      "           1       0.75      0.37      0.49       216\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.80      0.67      0.70      1000\n",
      "weighted avg       0.83      0.84      0.81      1000\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Resultados del entrenamiento con Máquina de Soporte Vectorial (SVM)\n",
      "CONJUNTO: SUPPORT VECTOR MACHINE - CONJUNTO 2L\n",
      "-------------------------------------------------------------------\n",
      "Accuracy: 0.856\n",
      "-------------------------------------------------------------------\n",
      "Matriz de Confusión\n",
      "-------------------------------\n",
      "[[761  23]\n",
      " [121  95]]\n",
      "-------------------------------------------------------------------\n",
      "Reporte de Clasificación\n",
      "-------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       784\n",
      "           1       0.81      0.44      0.57       216\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.83      0.71      0.74      1000\n",
      "weighted avg       0.85      0.86      0.84      1000\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Resultados del entrenamiento con Máquina de Soporte Vectorial (SVM)\n",
      "CONJUNTO: SUPPORT VECTOR MACHINE - CONJUNTO 3L\n",
      "-------------------------------------------------------------------\n",
      "Accuracy: 0.855\n",
      "-------------------------------------------------------------------\n",
      "Matriz de Confusión\n",
      "-------------------------------\n",
      "[[758  26]\n",
      " [119  97]]\n",
      "-------------------------------------------------------------------\n",
      "Reporte de Clasificación\n",
      "-------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       784\n",
      "           1       0.79      0.45      0.57       216\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.83      0.71      0.74      1000\n",
      "weighted avg       0.85      0.85      0.84      1000\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Resultados del entrenamiento con Máquina de Soporte Vectorial (SVM)\n",
      "CONJUNTO: SUPPORT VECTOR MACHINE - CONJUNTO 4L\n",
      "-------------------------------------------------------------------\n",
      "Accuracy: 0.863\n",
      "-------------------------------------------------------------------\n",
      "Matriz de Confusión\n",
      "-------------------------------\n",
      "[[764  20]\n",
      " [117  99]]\n",
      "-------------------------------------------------------------------\n",
      "Reporte de Clasificación\n",
      "-------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       784\n",
      "           1       0.83      0.46      0.59       216\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.85      0.72      0.75      1000\n",
      "weighted avg       0.86      0.86      0.85      1000\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Resultados del entrenamiento con Máquina de Soporte Vectorial (SVM)\n",
      "CONJUNTO: SUPPORT VECTOR MACHINE - CONJUNTO 1S\n",
      "-------------------------------------------------------------------\n",
      "Accuracy: 0.847\n",
      "-------------------------------------------------------------------\n",
      "Matriz de Confusión\n",
      "-------------------------------\n",
      "[[765  19]\n",
      " [134  82]]\n",
      "-------------------------------------------------------------------\n",
      "Reporte de Clasificación\n",
      "-------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91       784\n",
      "           1       0.81      0.38      0.52       216\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.83      0.68      0.71      1000\n",
      "weighted avg       0.84      0.85      0.82      1000\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Resultados del entrenamiento con Máquina de Soporte Vectorial (SVM)\n",
      "CONJUNTO: SUPPORT VECTOR MACHINE - CONJUNTO 2S\n",
      "-------------------------------------------------------------------\n",
      "Accuracy: 0.859\n",
      "-------------------------------------------------------------------\n",
      "Matriz de Confusión\n",
      "-------------------------------\n",
      "[[763  21]\n",
      " [120  96]]\n",
      "-------------------------------------------------------------------\n",
      "Reporte de Clasificación\n",
      "-------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.92       784\n",
      "           1       0.82      0.44      0.58       216\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.84      0.71      0.75      1000\n",
      "weighted avg       0.85      0.86      0.84      1000\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Resultados del entrenamiento con Máquina de Soporte Vectorial (SVM)\n",
      "CONJUNTO: SUPPORT VECTOR MACHINE - CONJUNTO 3S\n",
      "-------------------------------------------------------------------\n",
      "Accuracy: 0.855\n",
      "-------------------------------------------------------------------\n",
      "Matriz de Confusión\n",
      "-------------------------------\n",
      "[[758  26]\n",
      " [119  97]]\n",
      "-------------------------------------------------------------------\n",
      "Reporte de Clasificación\n",
      "-------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       784\n",
      "           1       0.79      0.45      0.57       216\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.83      0.71      0.74      1000\n",
      "weighted avg       0.85      0.85      0.84      1000\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Resultados del entrenamiento con Máquina de Soporte Vectorial (SVM)\n",
      "CONJUNTO: SUPPORT VECTOR MACHINE - CONJUNTO 4S\n",
      "-------------------------------------------------------------------\n",
      "Accuracy: 0.869\n",
      "-------------------------------------------------------------------\n",
      "Matriz de Confusión\n",
      "-------------------------------\n",
      "[[763  21]\n",
      " [110 106]]\n",
      "-------------------------------------------------------------------\n",
      "Reporte de Clasificación\n",
      "-------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       784\n",
      "           1       0.83      0.49      0.62       216\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.85      0.73      0.77      1000\n",
      "weighted avg       0.87      0.87      0.86      1000\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fit_and_tune_svm(x_train, y_train, x_test, y_test, custom_grid = None) -> dict:\n",
    "    \"\"\"\n",
    "    Searches for the best hyperparameters for a svm classifier using x_train and y_train\n",
    "    Fits a svm classifier using x_train and y_train\n",
    "    Calculates classification metrics and returns it with the model\n",
    "    Hyperparameters are tuned\n",
    "    :returns: dict with keys\n",
    "        - model: SVClassifier\n",
    "        - accuracy: float\n",
    "        - confusion_matrix: np.array\n",
    "        - classification_report: str\n",
    "    \"\"\"\n",
    "    param_grid = custom_grid if custom_grid else {\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=-1, refit=True)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    svm = grid_search.best_estimator_\n",
    "    y_pred = svm.predict(x_test)\n",
    "    return {\n",
    "        'model': svm,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'classification_report': classification_report(y_test, y_pred, zero_division=0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1L_tune_results = fit_and_tune_svm(x1L_train, y_train, x1L_test, y_test)\n",
    "pickle.dump(svm1L_results, open('svm/tuned_svm1L_results.pkl', 'wb'))\n",
    "show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 1L\",svm1L_tune_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm2L_tune_results = fit_and_tune_svm(x2L_train, y_train, x2L_test, y_test)\n",
    "pickle.dump(svm2L_results, open('svm/tuned_svm2L_results.pkl', 'wb'))\n",
    "show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 2L\",svm2L_tune_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm3L_tune_results = fit_and_tune_svm(x3L_train, y_train, x3L_test, y_test)\n",
    "pickle.dump(svm3L_results, open('svm/tuned_svm3L_results.pkl', 'wb'))\n",
    "show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 3L\",svm3L_tune_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm4L_tune_results = fit_and_tune_svm(x4L_train, y_train, x4L_test, y_test)\n",
    "pickle.dump(svm4L_results, open('svm/tuned_svm4L_results.pkl', 'wb'))\n",
    "show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 4L\",svm4L_tune_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1S_tune_results = fit_and_tune_svm(x1S_train, y_train, x1S_test, y_test)\n",
    "pickle.dump(svm1S_results, open('svm/tuned_svm1S_results.pkl', 'wb'))\n",
    "show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 1S\",svm1S_tune_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm2S_tune_results = fit_and_tune_svm(x2S_train, y_train, x2S_test, y_test)\n",
    "pickle.dump(svm2S_results, open('svm/tuned_svm2S_results.pkl', 'wb'))\n",
    "show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 2S\",svm2S_tune_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm3S_tune_results = fit_and_tune_svm(x3S_train, y_train, x3S_test, y_test)\n",
    "pickle.dump(svm3S_results, open('svm/tuned_svm3S_results.pkl', 'wb'))\n",
    "show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 3S\",svm3S_tune_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm4S_tune_results = fit_and_tune_svm(x4S_train, y_train, x4S_test, y_test)\n",
    "pickle.dump(svm4S_results, open('svm/tuned_svm4S_results.pkl', 'wb'))\n",
    "show_model_results(\"SUPPORT VECTOR MACHINE - CONJUNTO 4S\",svm4S_tune_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def fit_and_tune_random_forest(x_train, y_train, x_test, y_test) -> dict:\n",
    "    \"\"\"\n",
    "    Searches for the best hyperparameters for a random forest classifier using x_train and y_train\n",
    "    Fits a random forest classifier using x_train and y_train\n",
    "    Calculates classification metrics and returns it with the model\n",
    "    Hyperparameters are tuned\n",
    "    :returns: dict with keys\n",
    "        - model: RandomForestClassifier\n",
    "        - accuracy: float\n",
    "        - confusion_matrix: np.array\n",
    "        - classification_report: str\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': [10, 50, 100, 200, 500],\n",
    "        'max_depth': [None, 2, 5, 10],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, n_jobs=-1, refit=True)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    rf = grid_search.best_estimator_\n",
    "    y_pred = rf.predict(x_test)\n",
    "    return {\n",
    "        'model': rf,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'classification_report': classification_report(y_test, y_pred, zero_division=0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rfc1L_results = fit_and_tune_random_forest(x1L_train, y_train, x1L_test, y_test)\n",
    "pickle.dump(tuned_rfc1L_results, open('rfc/tuned_rfc1L_results.pkl', 'wb'))\n",
    "show_model_results(\"RANDOM FOREST CLASSIFIER - CONJUNTO 1L\", tuned_rfc1L_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rfc2L_results = fit_and_tune_random_forest(x2L_train, y_train, x2L_test, y_test)\n",
    "pickle.dump(tuned_rfc2L_results, open('rfc/tuned_rfc2L_results.pkl', 'wb'))\n",
    "show_model_results(\"RANDOM FOREST CLASSIFIER - CONJUNTO 2L\", tuned_rfc2L_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rfc3L_results = fit_and_tune_random_forest(x3L_train, y_train, x3L_test, y_test)\n",
    "pickle.dump(tuned_rfc3L_results, open('rfc/tuned_rfc3L_results.pkl', 'wb'))\n",
    "show_model_results(\"RANDOM FOREST CLASSIFIER - CONJUNTO 3L\", tuned_rfc3L_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rfc4L_results = fit_and_tune_random_forest(x4L_train, y_train, x4L_test, y_test)\n",
    "pickle.dump(tuned_rfc4L_results, open('rfc/tuned_rfc4L_results.pkl', 'wb'))\n",
    "show_model_results(\"RANDOM FOREST CLASSIFIER - CONJUNTO 4L\", tuned_rfc4L_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rfc1S_results = fit_and_tune_random_forest(x1S_train, y_train, x1S_test, y_test)\n",
    "pickle.dump(tuned_rfc1S_results, open('rfc/tuned_rfc1S_results.pkl', 'wb'))\n",
    "show_model_results(\"RANDOM FOREST CLASSIFIER - CONJUNTO 1S\", tuned_rfc1S_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rfc2S_results = fit_and_tune_random_forest(x2S_train, y_train, x2S_test, y_test)\n",
    "pickle.dump(tuned_rfc2S_results, open('rfc/tuned_rfc2S_results.pkl', 'wb'))\n",
    "show_model_results(\"RANDOM FOREST CLASSIFIER - CONJUNTO 2S\", tuned_rfc2S_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rfc3S_results = fit_and_tune_random_forest(x3S_train, y_train, x3S_test, y_test)\n",
    "pickle.dump(tuned_rfc3S_results, open('rfc/tuned_rfc3S_results.pkl', 'wb'))\n",
    "show_model_results(\"RANDOM FOREST CLASSIFIER - CONJUNTO 3S\", tuned_rfc3S_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rfc4S_results = fit_and_tune_random_forest(x4S_train, y_train, x4S_test, y_test)\n",
    "pickle.dump(tuned_rfc4S_results, open('rfc/tuned_rfc4S_results.pkl', 'wb'))\n",
    "show_model_results(\"RANDOM FOREST CLASSIFIER - CONJUNTO 4S\", tuned_rfc4S_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('backend-Te0t6uJi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0ca60a2cdb1d0849629b0665e6bc534f4c406f61de13067c8ff7809c9027b19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
